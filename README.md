# Grambahar Web Scraper

This project is a **Python Selenium-based web scraper** that extracts **product details, website logo, and contact information** from the Grambahar website:

ğŸ”— https://grambahar.com

The website is built using **Next.js / React**, so Selenium is used to handle dynamic, JavaScript-rendered content.

---

##  Features

###  Product Details Extraction
The scraper extracts **variant-level product information**, including:

- Product Name  
- Variant (e.g. `700gm`, `1.4kg + 1.5kg`)  
- Weight (grams & kilograms)  
- Selling Price (â‚¹)  
- Original Price (â‚¹)  
- Price per kilogram (calculated)

Each product variant is saved as a **separate row**, and duplicates are automatically removed.

---

###  Logo Extraction
- Identifies the official website logo from the header  
- Decodes Next.js optimized image URLs  
- Downloads and saves the **actual logo image** as `logo.png`

---

### Contact Information
- Extracts **email addresses** and **phone numbers** visible on the website  
- Uses regex-based text parsing on rendered page content  

---

##  Project Structure
grambahar_web_scraper/
â”‚
â”œâ”€â”€ products_scraper.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ output/
â”œâ”€â”€ product_variants.csv
â”œâ”€â”€ site_logo.csv
â”œâ”€â”€ contact_info.csv
â””â”€â”€ logo.png


---

## ğŸ“„ Output Files

### 1ï¸ `product_variants.csv`
Contains product and variant-level details.

**Columns:**
- Product Name  
- Variant  
- Weight (gm)  
- Weight (kg)  
- Selling Price (â‚¹)  
- Original Price (â‚¹)  
- Price per kg (â‚¹)

---

### 2ï¸ `site_logo.csv`
Stores reference to the downloaded logo image.

### 3ï¸ `contact_info.csv`
Stores extracted contact details (if publicly available).


---

## ğŸ›  Technologies Used

- Python 3  
- Selenium  
- WebDriver Manager  
- Requests  
- Regular Expressions (regex)  
- CSV handling  

---

##  How to Run

### 1. Install dependencies
```bash
pip install -r requirements.txt


---

##  Technologies Used

- Python 3  
- Selenium  
- WebDriver Manager  
- Requests  
- Regular Expressions (regex)  
- CSV handling  

---

. Run the scraper
python products_scraper.py

3. View results

All output files will be created inside the output/ directory.

